{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# FINAL TWITTER PORTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import time\n",
    "import json\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number 1A\n",
    "\n",
    "Create a 3rd table incorporating the Geo table (in addition to tweet and user tables that you already have) and extend your schema accordingly.\n",
    "You will need to generate an ID for the Geo table primary key (you may use any value or combination of values as long as it is unique) for that table and link it to the Tweet table (foreign key should be in the Tweet table because there can be multiple tweets sent from the same location). In addition to the primary key column, the geo table should have “type”, “longitude” and “latitude” columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SQLite connection\n",
    "conn = sqlite3.connect('tweets_DB.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "#Create tables\n",
    "create_user_tbl = '''CREATE TABLE Users (\n",
    "                id NUMBER(20),\n",
    "                name VARCHAR(90),\n",
    "                screen_name VARCHAR(90),\n",
    "                description VARCHAR(90),\n",
    "                friends_count INT\n",
    "                );'''\n",
    "\n",
    "create_geo_tbl = '''CREATE TABLE Geo ( \n",
    "                id NUMBER(20) PRIMARY KEY,\n",
    "                Type VARYCHAR(50), \n",
    "                Longitude VARCHAR(50),\n",
    "                Latitude VARCHAR(50)\n",
    "                );'''\n",
    "\n",
    "create_tweet_tbl = '''CREATE TABLE Tweets (\n",
    "                id NUMBER(20) PRIMARY KEY, \n",
    "                Created_Date DATE, \n",
    "                Text CHAR(140),\n",
    "                Source VARCHAR(200) DEFAULT NULL, \n",
    "                Reply_to_ID INT, \n",
    "                Reply_to_ScreenName VARCHAR(60), \n",
    "                Reply_to_StatusID INT, \n",
    "                Retweet_Cnt INT, \n",
    "                Contributors VARCHAR(200),\n",
    "                user_id INT,\n",
    "                geo_id INT,\n",
    "                FOREIGN KEY (user_id) REFERENCES Users(id),\n",
    "                FOREIGN KEY (geo_id) REFERENCES Geo(id)\n",
    "                );'''\n",
    "\n",
    "cur.execute(create_user_tbl)\n",
    "cur.execute(create_geo_tbl)\n",
    "cur.execute(create_tweet_tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number 1B\n",
    "\n",
    "Use python to download from the web and save to a local text file (not into database yet, just to text file) at least 500,000 lines worth of tweets. Test your code with fewer rows first – you can reduce the number of tweets if your computer is running too slow to handle 500K tweets. Report how long did it take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test tweets with .txt file\n",
    "wFD = urllib.request.urlopen('http://rasinsrv07.cstcis.cti.depaul.edu/CSC455/OneDayOfTweets.txt')\n",
    "#Limit readlines to 500000\n",
    "tweetLines = wFD.readlines(500000)\n",
    "#Create .txt to write to\n",
    "file = open('test_tweets.txt', 'w')\n",
    "\n",
    "#Write tweets to file\n",
    "for line in tweetLines:\n",
    "    file.write(str(line))\n",
    "\n",
    "#below is a process to see how long the file load took\n",
    "start = time.time()\n",
    "end = time.time()\n",
    "print (\"loadTweets took \", (end-start), ' seconds.')\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number 1C\n",
    "\n",
    "Repeat what you did in part-b, but instead of saving tweets to the file, populate the 3-table schema that you created in SQLite. Be sure to execute commit and verify that the data has been successfully loaded (report row counts for each of the 3 tables).\n",
    "How long did this step take?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load User Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Users Load fucntion\n",
    "def users_load(tweetLines):\n",
    "    #Batch size\n",
    "    batchRows = 50\n",
    "    batchedInserts = []\n",
    "\n",
    "#Insert loop\n",
    "    while len(tweetLines) > 0:\n",
    "        #Remove first line\n",
    "        line = tweetLines.pop(0) \n",
    "        tweetDict = json.loads(line.decode('utf-8'))\n",
    "        newRow = [] \n",
    "        #tags\n",
    "        tweetKeys = ['id_str', 'name', 'screen_name', 'descriptions', 'friends_count']\n",
    "        \n",
    "        for key in tweetKeys:\n",
    "            if key not in list(tweetDict.keys()):\n",
    "                newRow.append(None)\n",
    "            # Treat '', [] and 'null' as NULL\n",
    "            elif tweetDict[key] in ['', [], 'null']:\n",
    "                newRow.append(None)\n",
    "            else:\n",
    "                newRow.append(tweetDict[key])\n",
    "\n",
    "        #Add the new row to the collected batch\n",
    "        batchedInserts.append(newRow)\n",
    "\n",
    "        #Check len\n",
    "        if len(batchedInserts) >= batchRows or len(tweetLines) == 0:\n",
    "            cur.executemany('INSERT INTO Users VALUES(?,?,?,?,?)', batchedInserts)\n",
    "            # Reset the batching process\n",
    "            batchedInserts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Geo Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Geo Load fucntion\n",
    "def geo_load(tweetLines):\n",
    "    #Batch size\n",
    "    batchRows = 50\n",
    "    batchedInserts = []\n",
    "\n",
    "#Insert loop\n",
    "    while len(tweetLines) > 0:\n",
    "        #Remove first line\n",
    "        line = tweetLines.pop(0) \n",
    "        tweetDict = json.loads(line.decode('utf-8'))\n",
    "        newRow = [] \n",
    "        #tags\n",
    "        tweetKeys = ['id_str', 'type', 'longitude', 'latitude']\n",
    "        \n",
    "        for key in tweetKeys:\n",
    "            if key not in list(tweetDict.keys()):\n",
    "                newRow.append(None)\n",
    "            # Treat '', [] and 'null' as NULL\n",
    "            elif tweetDict[key] in ['', [], 'null']:\n",
    "                newRow.append(None)\n",
    "            else:\n",
    "                newRow.append(tweetDict[key])\n",
    "\n",
    "        #Add the new row to the collected batch\n",
    "        batchedInserts.append(newRow)\n",
    "\n",
    "        #Check len\n",
    "        if len(batchedInserts) >= batchRows or len(tweetLines) == 0:\n",
    "            cur.executemany('INSERT INTO Geo VALUES(?,?,?,?)', batchedInserts)\n",
    "            # Reset the batching process\n",
    "            batchedInserts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Tweet Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tweet Load fucntion\n",
    "def tweet_load(tweetLines):\n",
    "    #Batch size\n",
    "    batchRows = 50\n",
    "    batchedInserts = []\n",
    "\n",
    "#Insert loop\n",
    "    while len(tweetLines) > 0:\n",
    "        #Remove first line\n",
    "        line = tweetLines.pop(0) \n",
    "        tweetDict = json.loads(line.decode('utf-8'))\n",
    "        newRow = [] \n",
    "        #tags\n",
    "        tweetKeys = ['id_str','created_at','text','source','in_reply_to_user_id', \n",
    "        'in_reply_to_screen_name', 'in_reply_to_status_id', 'retweet_count', 'contributors', 'user_id', 'geo']\n",
    "        \n",
    "        for key in tweetKeys:\n",
    "            if key not in list(tweetDict.keys()):\n",
    "                newRow.append(None)\n",
    "            # Treat '', [] and 'null as NULL\n",
    "            elif tweetDict[key] in ['', [], 'null']:\n",
    "                newRow.append(None)\n",
    "            else:\n",
    "                newRow.append(tweetDict[key])\n",
    "\n",
    "        #Add the new row to the collected batch\n",
    "        batchedInserts.append(newRow)\n",
    "\n",
    "        #Check len\n",
    "        if len(batchedInserts) >= batchRows or len(tweetLines) == 0:\n",
    "            cur.executemany('INSERT INTO Tweets VALUES(?,?,?,?,?,?,?,?,?,?,?)', batchedInserts)\n",
    "            # Reset the batching process\n",
    "            batchedInserts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Populate Database\n",
    "\n",
    "NOTE: Doing a straight readlines() started an infinite loop so I had to truncate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Connect to database\n",
    "start = time.time()\n",
    "conn = sqlite3.connect('tweets_DB.db')\n",
    "cur = conn.cursor()\n",
    "wFD = urllib.request.urlopen('http://rasinsrv07.cstcis.cti.depaul.edu/CSC455/OneDayOfTweets.txt')\n",
    "tweetLines = wFD.readlines(4350000)\n",
    "\n",
    "#Populate table\n",
    "users_load(tweetLines)\n",
    "\n",
    "#time\n",
    "end = time.time()\n",
    "print (\"loadTweets took \", (end - start), ' seconds.')\n",
    "print (\"Loaded \", cur.execute('SELECT COUNT(*) FROM Users').fetchall()[0], \" rows\")\n",
    "wFD.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Connect to database\n",
    "start = time.time()\n",
    "conn = sqlite3.connect('tweets_DB.db')\n",
    "cur = conn.cursor()\n",
    "wFD = urllib.request.urlopen('http://rasinsrv07.cstcis.cti.depaul.edu/CSC455/OneDayOfTweets.txt')\n",
    "tweetLines = wFD.readlines(4350000)\n",
    "\n",
    "#Populate table\n",
    "geo_load(tweetLines)\n",
    "\n",
    "#Time\n",
    "end = time.time()\n",
    "print (\"loadTweets took \", (end - start), ' seconds.')\n",
    "print (\"Loaded \", cur.execute('SELECT COUNT(*) FROM Geo').fetchall()[0], \" rows\")\n",
    "wFD.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Connect to database\n",
    "start = time.time()\n",
    "conn = sqlite3.connect('tweets_DB.db')\n",
    "cur = conn.cursor()\n",
    "wFD = urllib.request.urlopen('http://rasinsrv07.cstcis.cti.depaul.edu/CSC455/OneDayOfTweets.txt')\n",
    "tweetLines = wFD.readlines(4350000)\n",
    "\n",
    "#Populate table\n",
    "tweet_load(tweetLines)\n",
    "\n",
    "#Time\n",
    "end = time.time()\n",
    "print (\"loadTweets took \", (end - start), ' seconds.')\n",
    "print (\"Loaded \", cur.execute('SELECT COUNT(*) FROM Tweets').fetchall()[0], \" rows\")\n",
    "wFD.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## SQL Query 1\n",
    "\n",
    "Find tweets where tweet id_str contains “44” or “77” anywhere in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('tweet_DB.db')\n",
    "sql = '''SELECT * \n",
    "    FROM Tweets\n",
    "    WHERE CONTAINS(id, '\"44\" OR \"77')'''\n",
    "\n",
    "pd.read_sql_query(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Query 2\n",
    "\n",
    "Find how many unique values are there in the “in_reply_to_user_id” column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('tweet_DB.db')\n",
    "sql = '''SELECT COUNT (DISTINCT in_reply_to_user_id) AS Count_Unique_ReplyIDs\n",
    "    FROM Tweets'''\n",
    "\n",
    "pd.read_sql_query(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Query 3\n",
    "\n",
    "Find the average longitude and latitude value for each user name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('tweet_DB.db')\n",
    "sql = '''SELECT id, AVG(Longitude) AS Avg_Longitude, AVG(Latitude) AS Avg_Latitude\n",
    "    FROM Geo\n",
    "    GROUP BY id'''\n",
    "\n",
    "pd.read_sql_query(sql, conn)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
